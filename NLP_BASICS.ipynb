{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "29c71a0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "import nltk\n",
    "\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6644447d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to C:\\Users\\Bhavna\n",
      "[nltk_data]     kumawat\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Unzipping corpora\\stopwords.zip.\n",
      "[nltk_data] Downloading package wordnet to C:\\Users\\Bhavna\n",
      "[nltk_data]     kumawat\\AppData\\Roaming\\nltk_data...\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('stopwords')\n",
    "nltk.download('wordnet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3bf0bbef",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Natural Language Processing (NLP) is a field o...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>It works with text and speech data like messag...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NLP is used in chatbots,search engines and voi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Common NLP tasks include tokenization, sentime...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>NLP makes human–computer interaction easier an...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text\n",
       "0  Natural Language Processing (NLP) is a field o...\n",
       "1  It works with text and speech data like messag...\n",
       "2  NLP is used in chatbots,search engines and voi...\n",
       "3  Common NLP tasks include tokenization, sentime...\n",
       "4  NLP makes human–computer interaction easier an..."
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data={\n",
    "    \"text\":[\n",
    "        \"Natural Language Processing (NLP) is a field of IT that helps computers understand human language.\",\n",
    "\"It works with text and speech data like messages, emails, and voice commands.\",\n",
    "\"NLP is used in chatbots,search engines and voice assistants.\",\n",
    "\"Common NLP tasks include tokenization, sentiment analysis, and text classification.\",\n",
    "\"NLP makes human–computer interaction easier and smarter.\"\n",
    "    ]\n",
    "}\n",
    "df=pd.DataFrame(data)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "7ef26260",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def clean_text(text):\n",
    "    text = text.lower()\n",
    "    text = re.sub(r'[^a-z\\s]', '', text)\n",
    "    words = text.split()\n",
    "    words = [w for w in words if w not in stop_words]\n",
    "    words = [lemmatizer.lemmatize(w) for w in words]\n",
    "    return \" \".join(words)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "24f6bd48",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>clean_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Natural Language Processing (NLP) is a field o...</td>\n",
       "      <td>natural language processing nlp field help com...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>It works with text and speech data like messag...</td>\n",
       "      <td>work text speech data like message email voice...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NLP is used in chatbots,search engines and voi...</td>\n",
       "      <td>nlp used chatbotssearch engine voice assistant</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Common NLP tasks include tokenization, sentime...</td>\n",
       "      <td>common nlp task include tokenization sentiment...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>NLP makes human–computer interaction easier an...</td>\n",
       "      <td>nlp make humancomputer interaction easier smarter</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  \\\n",
       "0  Natural Language Processing (NLP) is a field o...   \n",
       "1  It works with text and speech data like messag...   \n",
       "2  NLP is used in chatbots,search engines and voi...   \n",
       "3  Common NLP tasks include tokenization, sentime...   \n",
       "4  NLP makes human–computer interaction easier an...   \n",
       "\n",
       "                                          clean_text  \n",
       "0  natural language processing nlp field help com...  \n",
       "1  work text speech data like message email voice...  \n",
       "2     nlp used chatbotssearch engine voice assistant  \n",
       "3  common nlp task include tokenization sentiment...  \n",
       "4  nlp make humancomputer interaction easier smarter  "
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['clean_text']=df[\"text\"].apply(clean_text)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "a0119ff4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vocabulary:\n",
      " ['analysis' 'assistant' 'chatbotssearch' 'classification' 'command'\n",
      " 'common' 'computer' 'data' 'easier' 'email' 'engine' 'field' 'help'\n",
      " 'human' 'humancomputer' 'include' 'interaction' 'language' 'like' 'make'\n",
      " 'message' 'natural' 'nlp' 'processing' 'sentiment' 'smarter' 'speech'\n",
      " 'task' 'text' 'tokenization' 'understand' 'used' 'voice' 'work']\n",
      "\n",
      "TF-TDF Matrix:\n",
      " [[0.         0.         0.         0.         0.         0.\n",
      "  0.29725329 0.         0.         0.         0.         0.29725329\n",
      "  0.29725329 0.29725329 0.         0.         0.         0.59450658\n",
      "  0.         0.         0.         0.29725329 0.16746732 0.29725329\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.29725329 0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.34706676 0.\n",
      "  0.         0.34706676 0.         0.34706676 0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.34706676 0.         0.34706676 0.         0.         0.\n",
      "  0.         0.         0.34706676 0.         0.28001128 0.\n",
      "  0.         0.         0.28001128 0.34706676]\n",
      " [0.         0.44863732 0.44863732 0.         0.         0.\n",
      "  0.         0.         0.         0.         0.44863732 0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.25275444 0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.44863732 0.36195776 0.        ]\n",
      " [0.3542556  0.         0.         0.3542556  0.         0.3542556\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.3542556  0.         0.\n",
      "  0.         0.         0.         0.         0.19958143 0.\n",
      "  0.3542556  0.         0.         0.3542556  0.28581119 0.3542556\n",
      "  0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.43366097 0.         0.         0.\n",
      "  0.         0.         0.43366097 0.         0.43366097 0.\n",
      "  0.         0.43366097 0.         0.         0.24431703 0.\n",
      "  0.         0.43366097 0.         0.         0.         0.\n",
      "  0.         0.         0.         0.        ]]\n"
     ]
    }
   ],
   "source": [
    "tfidf=TfidfVectorizer()\n",
    "x=tfidf.fit_transform(df[\"clean_text\"])\n",
    "\n",
    "print(\"Vocabulary:\\n\",tfidf.get_feature_names_out())\n",
    "print(\"\\nTF-TDF Matrix:\\n\",x.toarray())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "d3cbe76e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>analysis</th>\n",
       "      <th>assistant</th>\n",
       "      <th>chatbotssearch</th>\n",
       "      <th>classification</th>\n",
       "      <th>command</th>\n",
       "      <th>common</th>\n",
       "      <th>computer</th>\n",
       "      <th>data</th>\n",
       "      <th>easier</th>\n",
       "      <th>email</th>\n",
       "      <th>...</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>smarter</th>\n",
       "      <th>speech</th>\n",
       "      <th>task</th>\n",
       "      <th>text</th>\n",
       "      <th>tokenization</th>\n",
       "      <th>understand</th>\n",
       "      <th>used</th>\n",
       "      <th>voice</th>\n",
       "      <th>work</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.297253</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.297253</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.347067</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.347067</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.347067</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.347067</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.280011</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.280011</td>\n",
       "      <td>0.347067</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.448637</td>\n",
       "      <td>0.448637</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.448637</td>\n",
       "      <td>0.361958</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.354256</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.354256</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.354256</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.354256</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.354256</td>\n",
       "      <td>0.285811</td>\n",
       "      <td>0.354256</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.433661</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.433661</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 34 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   analysis  assistant  chatbotssearch  classification   command    common  \\\n",
       "0  0.000000   0.000000        0.000000        0.000000  0.000000  0.000000   \n",
       "1  0.000000   0.000000        0.000000        0.000000  0.347067  0.000000   \n",
       "2  0.000000   0.448637        0.448637        0.000000  0.000000  0.000000   \n",
       "3  0.354256   0.000000        0.000000        0.354256  0.000000  0.354256   \n",
       "4  0.000000   0.000000        0.000000        0.000000  0.000000  0.000000   \n",
       "\n",
       "   computer      data    easier     email  ...  sentiment   smarter    speech  \\\n",
       "0  0.297253  0.000000  0.000000  0.000000  ...   0.000000  0.000000  0.000000   \n",
       "1  0.000000  0.347067  0.000000  0.347067  ...   0.000000  0.000000  0.347067   \n",
       "2  0.000000  0.000000  0.000000  0.000000  ...   0.000000  0.000000  0.000000   \n",
       "3  0.000000  0.000000  0.000000  0.000000  ...   0.354256  0.000000  0.000000   \n",
       "4  0.000000  0.000000  0.433661  0.000000  ...   0.000000  0.433661  0.000000   \n",
       "\n",
       "       task      text  tokenization  understand      used     voice      work  \n",
       "0  0.000000  0.000000      0.000000    0.297253  0.000000  0.000000  0.000000  \n",
       "1  0.000000  0.280011      0.000000    0.000000  0.000000  0.280011  0.347067  \n",
       "2  0.000000  0.000000      0.000000    0.000000  0.448637  0.361958  0.000000  \n",
       "3  0.354256  0.285811      0.354256    0.000000  0.000000  0.000000  0.000000  \n",
       "4  0.000000  0.000000      0.000000    0.000000  0.000000  0.000000  0.000000  \n",
       "\n",
       "[5 rows x 34 columns]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tfidf_df=pd.DataFrame(\n",
    "    x.toarray(),\n",
    "    columns=tfidf.get_feature_names_out()\n",
    ")\n",
    "tfidf_df"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
